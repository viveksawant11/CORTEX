{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_PROJECT'] = 'cortex'\n",
    "\n",
    "# Get keys from the environment\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if langchain_api_key:\n",
    "    os.environ['LANGCHAIN_API_KEY'] = langchain_api_key\n",
    "else:\n",
    "    raise ValueError(\"LANGCHAIN_API_KEY is not set in the environment.\")\n",
    "\n",
    "if groq_api_key:\n",
    "    os.environ['GROQ_API_KEY'] = groq_api_key\n",
    "else:\n",
    "    raise ValueError(\"GROQ_API_KEY is not set in the environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 12 - MULTI-REPRESENTATION INDEXING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Configure headers directly in the loader\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Load documents with headers\n",
    "loader1 = WebBaseLoader(\n",
    "    web_paths=(\"https://medium.com/@pankaj_pandey/introduction-to-retrieval-augmented-generation-rag-9209bf8a076d\",),\n",
    "    requests_kwargs={\"headers\": headers}\n",
    ")\n",
    "docs = loader1.load()\n",
    "\n",
    "loader2 = WebBaseLoader(\n",
    "    web_paths=(\"https://medium.com/humansdotai/an-introduction-to-ai-agents-e8c4afd2ee8f\",),\n",
    "    requests_kwargs={\"headers\": headers}\n",
    ")\n",
    "docs.extend(loader2.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")\n",
    "    | ChatGroq(model=\"llama3-70b-8192\", temperature=0)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "summaries = chain.batch(docs, {\"max_concurrency\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The article introduces Retrieval-Augmented Generation (RAG), a framework that improves the accuracy and reliability of Large Language Models (LLMs) by incorporating factual information during response generation. RAG addresses the drawbacks of LLMs, including knowledge cutoff, inconsistency, and response hallucination.\\n\\nRAG consists of two phases: retrieval and content generation. In the retrieval phase, algorithms search for and retrieve relevant information from external knowledge bases. This information is then used in the generative phase, where the LLM synthesizes an answer based on both the augmented prompt and its internal representation of training data.\\n\\nThe benefits of RAG include:\\n\\n* Accuracy and fact-checking: Ensures LLM responses are based on reliable sources, allowing users to verify claims.\\n* Reduced bias and hallucination: Limits LLM reliance on internal biases and prevents fabrication of information.\\n* Lower cost and maintenance: Reduces the need for continuous LLM retraining and updates, saving computational resources.\\n\\nRAG has applications in personalized responses, verifiable answers, and lowering computational and financial costs in enterprise settings. The implementation of RAG involves an \"open-book\" approach, where LLMs respond to questions by browsing through external content.\\n\\nThe article also discusses the challenges and ongoing innovations in RAG, including improving retrieval algorithms, optimizing generation techniques, and training LLMs to recognize \"unknowns\" and avoid making things up. The article concludes that RAG is a promising approach for improving LLM accuracy and reliability, offering benefits like factual grounding, reduced bias, and lower maintenance costs.',\n",
       " 'The article introduces Artificial Intelligence (AI) Agents, which are digital systems that can perform autonomously, make decisions, and interact with their environment like humans. Powered by machine learning, natural language processing, and other cutting-edge technologies, AI Agents can learn from data, adapt to new information, and execute complex functions autonomously.\\n\\nThe article explores the functionalities, technology, and applications of AI Agents across industries, including customer service, healthcare, finance, transportation, and more. It also discusses the ethical considerations that arise as these agents become increasingly integrated into our lives.\\n\\nAI Agents are designed to understand, analyze, and respond to human input, constantly evolving to enhance their capabilities. They can operate independently, driven by goals rather than specific inputs, and can adapt to new information and environments, evolving with every task to achieve their objectives optimally.\\n\\nThe article highlights the characteristics of AI Agents, including enhanced efficiency, tailored personalization, unmatched scalability, always-on availability, and reduced costs. It also explores how AI Agents are revolutionizing the economy, transforming businesses, and shaping the future with their unparalleled versatility and transformative capabilities.\\n\\nThe article categorizes AI Agents into different types, including simple reflex agents, model-based reflex agents, goal-based agents, utility-based AI agents, learning agents, and hierarchical AI agents. Each type is designed to address specific business challenges within their designated domains.\\n\\nFinally, the article concludes that AI Agents have the potential to revolutionize various industries, but responsible and beneficial utilization of these agents is essential for enterprises venturing into this transformative journey.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain_core.documents import Document\n",
    "import uuid\n",
    "\n",
    "# Initialize HuggingFace embeddings with the updated class\n",
    "model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "\n",
    "# Initialize the vectorstore for indexing child chunks with the updated class\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"summaries\",\n",
    "    embedding_function=hf_embeddings\n",
    ")\n",
    "\n",
    "# Initialize the storage layer for parent documents\n",
    "store = InMemoryByteStore()\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# Create the retriever combining vectorstore and byte storage\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key\n",
    ")\n",
    "\n",
    "# Generate unique document IDs\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "\n",
    "# Create Document objects for summaries with linked metadata\n",
    "summary_docs = [\n",
    "    Document(page_content=summary, metadata={id_key: doc_ids[i]})\n",
    "    for i, summary in enumerate(summaries)\n",
    "]\n",
    "\n",
    "# Add summary documents to the vectorstore\n",
    "retriever.vectorstore.add_documents(summary_docs)\n",
    "\n",
    "# Link parent documents to their corresponding IDs in the byte store\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['108f3a67-ba87-4454-ad62-57b9a81bbf77',\n",
       " '8b6ab1e8-e3a4-4fc5-aa37-c62aa9a1e93f']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://medium.com/@pankaj_pandey/introduction-to-retrieval-augmented-generation-rag-9209bf8a076d', 'title': 'Introduction to Retrieval-Augmented Generation (RAG) | by Pankaj | Medium', 'description': 'The world is advancing rapidly, introducing new technologies and stacks in AI and other areas every day. Large Language Models (LLMs) are a significant innovation in this space. However, LLMs have…', 'language': 'en'}, page_content='Introduction to Retrieval-Augmented Generation (RAG) | by Pankaj | MediumOpen in appSign upSign inWriteSign upSign inMastodonIntroduction to Retrieval-Augmented Generation (RAG)PankajFollow6 min read·Dec 16, 2023--ListenShareRAG systems aim to address the drawbacks of Large Language Models by incorporating factual information during response generation, mitigating issues such as knowledge cutoff and response hallucination.Retrieval Augmented Generation (RAG)The world is advancing rapidly, introducing new technologies and stacks in AI and other areas every day. Large Language Models (LLMs) are a significant innovation in this space. However, LLMs have drawbacks due to their knowledge cutoff and other reasons, leading to confident but inaccurate responses. The RAG systems aim to address this issue by incorporating factual information during response generation to prevent hallucination and retrieve accurate responses.Introduction:RAG is an AI framework that improves the accuracy and reliability of large language models (LLMs) by grounding them in external knowledge bases.LLMs can be inconsistent and prone to errors, lacking true understanding of word meaning.RAG addresses these issues by providing access to up-to-date facts and verifiable sources, increasing user trust.Purpose of RAG:Grounding LLMs on external knowledge for improved responses.Overcoming inconsistencies in LLM-generated answers.Challenges Addressed by RAG:Inconsistency in LLM responses.Lack of understanding of the meaning of words by LLMs.Reduction of opportunities for the model to leak sensitive data.Benefits of RAG:Accuracy and Fact-Checking:Ensures LLM responses are based on reliable sources, allowing users to verify claims.Reduced Bias and Hallucination:Limits LLM reliance on internal biases and prevents fabrication of information.Lower Cost and Maintenance:Reduces the need for continuous LLM retraining and updates, saving computational resources.How RAG Works:RAG consists of two distinct phases: retrieval and content generation. In the retrieval phase, algorithms search for and retrieve relevant information from external knowledge bases. This information is then used in the generative phase, where the LLM synthesizes an answer based on both the augmented prompt and its internal representation of training data.Phase 1: RetrievalRelevant information is retrieved from external sources based on the user\\'s prompt or question.Sources vary depending on the context (open-domain internet vs. closed-domain enterprise data).Phase 2: Content GenerationThe retrieved information is appended to the user\\'s prompt and fed to the LLM.The LLM generates a personalized answer based on the augmented prompt and its internal knowledge base.The answer can be delivered with links to its sources for transparency.Advantages and Applications of RAGRAG offers several advantages, including access to the latest, reliable facts, reduction in sensitive data leakage and decreased need for continuous model retraining. It finds applications in personalized responses, verifiable answers and lowering computational and financial costs in enterprise settings.Access to current and reliable information.Reduced opportunities for sensitive data leakage.Lower computational and financial costs in LLM-powered applications.Implementation and WorkflowsRAG operates in an “open book” manner, allowing LLMs to respond to questions by browsing through external content. It involves a retrieval phase, where relevant information is gathered and a generative phase, where the LLM synthesizes a response using both external and internal knowledge.Open-Book Approach:Contrasted with closed-book exams, where LLMs rely on memory.Model’s response involves browsing through external content.Workflow:Retrieval phase: Search and gather external information.Generative phase: Synthesize a personalized answer using internal and external knowledge.Teaching LLMs to Recognize LimitationsLLMs, when faced with ambiguous or complex queries, may provide inaccurate responses. RAG helps in training LLMs to recognize unanswerable questions and prompts them to either admit uncertainty or ask clarifying questions.Recognition of Limitations:LLMs prone to making things up in challenging scenarios.Training LLMs to explicitly recognize unanswerable questions.Challenges and Ongoing Innovations in Retrieval-Augmented GenerationWhile RAG is a powerful tool, there are still some challenges persist and ongoing innovations are necessary. Lots of Research is focused on improving both the retrieval and generation ends of the process to enhance the effectiveness of RAG.Challenges:Imperfections in RAG.Enriching prompts with relevant information using vectors.Innovations and Research:Focus on retrieval: Finding and fetching the most relevant information.Focus on generation: Structuring information for richer responses.Example Scenario: Customer Care ChatbotAlice, an employee, asks about taking vacation in half-day increments.The LLM retrieves relevant data from Alice\\'s HR files and company policies.It generates a personalized answer confirming her vacation allowance and half-day eligibility.The answer is delivered with links to the HR files and policies for verification.Challenges and Future DirectionsTraining LLMs to recognize \"unknowns\" and avoid making things up.Improving retrieval algorithms for finding the most relevant information.Optimizing generation techniques for incorporating retrieved information effectively.Python Code Examples:1. Simple Retrieval with Elasticsearch:from elasticsearch import Elasticsearches = Elasticsearch()query = \"early dismissal school Wednesdays\"results = es.search(index=\"documents\", query={\"query\": {\"match\": {\"text\": query}}})# Process results and use them to augment the LLM prompt...2. Combining Retrieval and Generation with Transformers:# Using a transformer-based model with RAG for information retrieval and generationfrom transformers import pipelinerag_qa_pipeline = pipeline(\"question-answering\", model=\"facebook/rag-token-base\", retriever=\"facebook/rag-token-base\")question = \"What is retrieval-augmented generation?\"answer = rag_qa_pipeline(question, truncation=True, return_prompt=True)print(answer)from transformers import AutoTokenizer, AutoModelForSequenceClassificationtokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")model = AutoModelForSequenceClassification.from_pretrained(\"rag/bert-base-uncased-rag\")prompt = \"Alice asks about taking vacation in half-day increments.\"retrieved_info = ...  # Retrieved information from external sourceencoded_prompt = tokenizer(prompt + retrieved_info, return_tensors=\"pt\")output = model(**encoded_prompt)# Process output and use it to generate the LLM response...# Sample Python code demonstrating the retrieval phase in RAGdef retrieval_phase(user_prompt, external_data):    # Algorithm to search and retrieve relevant information    retrieved_info = search_and_retrieve(user_prompt, external_data)    return retrieved_info# Sample Python code demonstrating the generative phase in RAGdef generative_phase(augmented_prompt, internal_data):    # Algorithm to synthesize a personalized answer using internal and external knowledge    answer = generate_response(augmented_prompt, internal_data)    return answer3. RAG Example in a question answering system:# Example of using RAG in a question answering systemfrom transformers import RagTokenizer, RagRetriever, RagSequenceForGenerationtokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-base\")retriever = RagRetriever.from_pretrained(\"facebook/rag-token-base\")model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-base\")# Retrieve relevant informationinput_text = \"What is retrieval-augmented generation?\"retrieved_info = retriever.retrieve(input_text)# Generate response using RAGgenerated_response = model.generate(**retrieved_info)print(tokenizer.decode(generated_response[0], skip_special_tokens=True))4. Personalized and Verifiable Responses with RAGRetrieval-augmented generation (RAG) enables large language models (LLMs) to provide personalized responses without constant retraining. It reduces the need for manual scripting in chatbots, allowing the model to adapt to new information dynamically.# Using RAG to generate personalized responses in a chatbotfrom transformers import RagRetriever, RagSequenceForGenerationretriever = RagRetriever.from_pretrained(\"facebook/rag-token-base\")model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-base\")# User\\'s queryuser_query = \"Can I take vacation in half-day increments?\"# Retrieve relevant informationretrieved_info = retriever.retrieve(user_query)# Generate personalized response using RAGgenerated_response = model.generate(**retrieved_info)print(tokenizer.decode(generated_response[0], skip_special_tokens=True))5. Teaching the Model to Recognize UnknownsLLMs need explicit training to recognize and admit when they cannot answer certain questions. RAG addresses the challenge of ambiguous queries, complex questions and situations where the model lacks information.# Training an LLM to recognize unknown questions using RAGfrom transformers import RagRetriever, RagSequenceForGenerationretriever = RagRetriever.from_pretrained(\"facebook/rag-token-base\")model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-base\")# User\\'s ambiguous queryambiguous_query = \"How much vacation time do I have?\"# Retrieve relevant informationretrieved_info = retriever.retrieve(ambiguous_query)# Train the model to recognize unknowns# ...# Generate response using RAG, considering the unknown recognitiongenerated_response = model.generate(**retrieved_info)print(tokenizer.decode(generated_response[0], skip_special_tokens=True))Note: These are simplified examples to understand the basic concepts, the actual implementation may require more complex code and libraries depending on the specific use case and desired functionalities.Conclusion:RAG is a promising approach for improving LLM accuracy and reliability, offering benefits like factual grounding, reduced bias and lower maintenance costs. While challenges remain in areas like unknown recognition and retrieval optimization, ongoing research is pushing the boundaries of RAG capabilities and paving the way for more trustworthy and informative LLM applications.Supporting Information:Vector databases play a crucial role in RAG by efficiently indexing, storing and retrieving information.Lots of Research emphasizes the imperfections of RAG and the need for ongoing improvements in its implementation.Remember: This is a preliminary analysis. Further research and validation are needed to ensure the accuracy and completeness of the information presented.SourcesData-Science-Pipeline-DetectorRetrieval-augmented-generation-RAGLarge Language ModelsRagMachine LearningData ScienceAI----FollowWritten by Pankaj801 followers·11 followingExpert in software technologies with proficiency in multiple languages, experienced in Generative AI, NLP, Bigdata, and application development.FollowNo responses yetHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://medium.com/humansdotai/an-introduction-to-ai-agents-e8c4afd2ee8f', 'title': 'An Introduction to AI Agents. Artificial Intelligence Agents are the… | by Humans.ai | humansdotai | Medium', 'description': 'Artificial Intelligence Agents are the digital newcomers revolutionizing our world. These agents, often called AI bots or virtual assistants, are intelligent systems programmed to perform tasks, make…', 'language': 'en'}, page_content='An Introduction to AI Agents. Artificial Intelligence Agents are the… | by Humans.ai | humansdotai | MediumOpen in appSign upSign inWriteSign upSign inhumansdotai·Humans.ai utilizes blockchain technology to align artificial intelligence with trust, creating a human-centric approach. Our company views AI not as a tool but as a companion, envisioning a collaborative future with humanity.An Introduction to AI AgentsHumans.aiFollow7 min read·Dec 27, 2023--2ListenShareArtificial Intelligence Agents are the digital newcomers revolutionizing our world. These agents, often called AI bots or virtual assistants, are intelligent systems programmed to perform tasks, make decisions, and interact with their environment just like humans do. Powered by machine learning, natural language processing, and other cutting-edge technologies, AI Agents can learn from data, adapt to new information, and execute complex functions autonomously. They exist in various forms, from chatbots providing customer service to sophisticated robots created for healthcare and manufacturing. AI Agents are designed to understand, analyze, and respond to human input, constantly evolving to enhance their capabilities.In this article, we’ll delve into the world of AI agents, exploring their functionalities, the technology behind their intelligence, their applications across industries, and the ethical considerations that arise as these agents become increasingly integrated into our daily lives.Join us on an amazing journey through the fascinating world of AI agents and their transformative potential!Understanding AI AgentsAI Agents navigate their environments and accomplish goals autonomously, free from human intervention. These savvy programs address customer queries, and make fast decisions based on real-time information, revolutionizing the landscape of customer engagement. Think of them as the pioneers redefining our interactions — they’re simplifying business processes and customer communications with an adaptive finesse that transforms the ordinary into extraordinary.These agents work their magic by perceiving their surroundings and executing actions through a spectrum of tools — from rule-based systems and decision-makers to the benefits of machine learning. As digital decision-makers fueled by past and present inputs, AI Agents pursue optimal outcomes, slowly carving the path to a smarter and more intuitive future.AI Agents are revolutionizing the way we interact with technology. Unlike traditional AI interactions where prompts are necessary for responses, AI agents operate independently, driven by goals rather than specific inputs. They’re autonomous problem solvers, seamlessly adapting to new information and environments, evolving with every task to achieve their objectives optimally.In contrast to standard automation processes rooted in fixed parameters and training data, AI Agents flourish in uncertain landscapes, navigating uncharted territories and handling vast streams of fresh data. They’re the new face of intelligent automation. But AI Agents aren’t just intelligent; they’re adept at using computers. From browsing the internet and managing apps to conducting financial transactions and controlling devices, their capabilities are vast and versatile.More importantly, the emergence of AI Agents signifies a step towards Artificial General Intelligence (AGI), where machines will emulate human-like flexibility and unparalleled proficiency across diverse domains. AI Agents represent a groundbreaking step toward this future, where technology’s potential is unknown.How does an AI Agent work?AI Agents operate similarly to popular AI solutions present on the market, namely they require users to input an objective, after which the AI Agent initiates its journey toward the goal by engaging with the core Language Learning Models that operate in the background to return its first output and showcase its understanding of the task at hand.Next comes the meticulous crafting of a task list. Driven by the defined goal, the AI Agent formulates a sequence of tasks, prioritizing their order of completion. Once satisfied with its plan, it delves into information retrieval.Functioning like an experimented computer user, the Agent navigates the vast domain of the internet to gather relevant information. Some advanced agents collaborate with other AI models, enabling access to specialized tasks like image generation and computer vision functionalities. All the collected data is meticulously managed by the Agent and used to relay information back to the user and refine its strategy for more optimized progress.As each task is completed, the Agent actively seeks feedback, both from external sources and through its internal thought process, to estimate its distance from the ultimate goal. Until its objective is achieved, the agent relentlessly iterates, crafting new tasks and seeking more data and feedback to advance toward its goal.These are the fundamental steps a typical AI Agent follows to fulfill any given goal. Yet, the sequencing of steps may vary depending on the different configurations or objectives the AI agent was designed for.How AI Agents transform businessesAI Agents stand as catalysts, elevating the game for businesses by infusing tasks with heightened performance and supercharged outcomes. These agents take on tasks that either surpass human capabilities or liberate us from those tasks we’d rather not tackle. In business, AI Agents aren’t just tools; they’re game-changers, empowering enterprises to rise beyond limits and build new paths of efficiency, personalization, and cost-effectiveness. Overall, AI Agents serve as guardians against errors, the solvers of intricate puzzles, and the creators of new fields of opportunities.AI Agents Characteristics:✅ Enhanced Efficiency: AI Agents perform tasks with impeccable speed and accuracy, effortlessly surpassing humans. They’re the masters of repetitive tasks, allowing humans to focus their attention on complex problem-solving.✅ Tailored Personalization: AI Agents use data analytics to curate personalized customer solutions and recommendations.✅ Unmatched Scalability: Virtual agents boast adaptability like no other, effortlessly scaling their operations to meet the surge during peak seasons or unexpected demand spikes, empowering businesses with unparalleled flexibility.✅ Always On: These tireless digital agents operate around the clock, offering 24/7 customer service. No overtime, no weekend shifts, just unwavering availability.✅ Reduced Costs: By automating routine tasks, AI Agents are the tool that slashes labor costs for businesses. Moreover, they’re handling numerous customer inquiries simultaneously, reducing the need for additional staff.How AI Agents are revolutionizing the economyAI Agents have become indispensable across various business domains, revolutionizing service delivery, supply chains, and marketing strategies. These multifaceted AI Agents can become the backbone of modern business operations, shaping the future with their unparalleled versatility and transformative capabilities, serving as catalysts for transformative change, with examples transcending multiple industries:• Finance: Autonomous agents redefine trading, risk management, and fraud detection. Hedge funds leverage AI-powered agents to analyze market data and execute trades intelligently.• Energy: In power grids and energy markets, adaptive agents streamline operations, automating power generation and distribution with precision and efficiency.• Transportation: Automobile companies like Tesla utilize AI-based agents to develop self-driving cars. These autonomous agents make decisions based on sensory inputs, optimizing traffic flow and supply chain logistics. AI Agents can also help manage traffic flow and improve logistics and supply chain management.• Healthcare: Autonomous agents revolutionize diagnosis and treatment by analyzing medical records, crafting personalized treatment plans, and optimizing resource allocation.• Customer Service: Virtual assistants and AI-driven chatbots enhance customer service across diverse industries, ensuring seamless interactions.• Gaming: Intelligent agents enrich gaming experiences by creating challenging opponents in simulations, enhancing realism for players.• Smart Homes and Buildings: Agents optimize energy consumption and improve comfort by controlling heating, lighting, and other systems in smart homes and buildings.• Robotics: AI Agents can control robots and automate tasks, driving operational efficiency.• Natural Language Processing: Agents facilitate language translation, question answering, and chatbot communication, bridging gaps in user interactions.• Cybersecurity: AI Agents can bolster security measures by detecting intrusions, analyzing malware, and fortifying network security.• Environmental Monitoring: AI Agents contribute to sustainability efforts by monitoring natural resources, tracking climate changes, and enhancing environmental conservation.• Social Media: Agents analyze social media data, unveiling trends, patterns, and personalized recommendations, enriching user experiences.Categories of AI AgentsAI Agents operate nearly independently, navigating their surroundings, interpreting information, and making decisions based on keen observations. Different types of AI Agents are tailor-made to address specific business challenges within their designated domains.Classifying AI Agents involves discerning the impact of their actions on their perceived intelligence and capacities. By delving into the distinct traits of each agent category, there’s ample potential to elevate their efficiency and yield superior outcomes.Simple Reflex AgentsA simple reflex agent operates within predefined guidelines, reacting solely to immediate circumstances. It’s most effective in stable environments with straightforward actions, where its reactive nature suits the situation. Simple Reflex agents work based on condition-action rules, determining responses based on specific conditions.Model-Based Reflex AgentsA model-based Reflex Agent operates on a current percept and an internal state representing the hidden aspects of the world. It adapts its internal state based on how the world evolves and the impact of its actions on it. Model-based Reflex Agents work based on condition-action rules, which specify the appropriate action to take in a particular situation. Unlike simple reflex agents, they also factor in their internal state during decision-making.Goal-based AgentsGoal-based Agents leverage information from their surroundings to achieve defined objectives. Employing search algorithms, these agents efficiently navigate through their environments to reach their set goals.Also known as rule-based, they follow predefined directives to accomplish tasks and act based on specific conditions. They excel in handling complex tasks, finding their utility in robotics, computer vision, and natural language processing. Unlike their basic counterparts, goal-based agents identify optimal decision-making paths tailored to their desired outcomes or goals.Utility-Based AI AgentsUtility-based Agents aim to maximize utility functions or values. They cherry-pick actions with the highest expected utility, measuring how favorable the outcome is. Due to this design, utility-based Agents excel in navigating complex and uncertain scenarios, adapting flexibly to situations.Learning AgentsAI Learning Agents constantly enhance performance through the power of learning. These software agents start with basic knowledge and refine themselves through machine learning, constantly evolving to achieve better outcomes. AI learning agents observe, learn, and act based on feedback loops, constantly adapting to shape their behavior for future interactions.Hierarchical AI AgentsHierarchical Agents are organized in tiers, with higher-level agents orchestrating lower-level counterparts. These levels, tailored to the system’s complexity, excel in diverse fields like robotics, manufacturing, and transportation, adept at coordinating multiple tasks and sub-tasks seamlessly.ConclusionIn a generation characterized by rapid AI advancement, the trajectory of AI Agents promises unparalleled autonomy, capable of making independent decisions with minimal human oversight. Their potential spans across diverse industries, revolutionizing customer service, predicting market demands, optimizing production lines, and beyond.The extensive applications of AI Agents hint at vast promise, yet ethical considerations remain most important. Responsible and beneficial utilization of these Agents is essential for enterprises venturing into this transformative journey.Market analysis shows that the 2024 year it’s the moment to embrace the formidable power of AI Agents at the enterprise’s level.AIArtificial IntelligenceAi AgentAGITech----2FollowPublished in humansdotai1.2K followers·Last published\\xa0Oct 28, 2024Humans.ai utilizes blockchain technology to align artificial intelligence with trust, creating a human-centric approach. Our company views AI not as a tool but as a companion, envisioning a collaborative future with humanity.FollowFollowWritten by Humans.ai425 followers·4 followingHeart driven AIFollowResponses (2)See all responsesHelpStatusAboutCareersPressBlogPrivacyRulesTermsText to speech\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.docstore.mget(doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id='3c6c3615-0e8f-4dd9-adb0-4b673d28fa4b', metadata={'doc_id': '8b6ab1e8-e3a4-4fc5-aa37-c62aa9a1e93f'}, page_content='The article introduces Artificial Intelligence (AI) Agents, which are digital systems that can perform autonomously, make decisions, and interact with their environment like humans. Powered by machine learning, natural language processing, and other cutting-edge technologies, AI Agents can learn from data, adapt to new information, and execute complex functions autonomously.\\n\\nThe article explores the functionalities, technology, and applications of AI Agents across industries, including customer service, healthcare, finance, transportation, and more. It also discusses the ethical considerations that arise as these agents become increasingly integrated into our lives.\\n\\nAI Agents are designed to understand, analyze, and respond to human input, constantly evolving to enhance their capabilities. They can operate independently, driven by goals rather than specific inputs, and can adapt to new information and environments, evolving with every task to achieve their objectives optimally.\\n\\nThe article highlights the characteristics of AI Agents, including enhanced efficiency, tailored personalization, unmatched scalability, always-on availability, and reduced costs. It also explores how AI Agents are revolutionizing the economy, transforming businesses, and shaping the future with their unparalleled versatility and transformative capabilities.\\n\\nThe article categorizes AI Agents into different types, including simple reflex agents, model-based reflex agents, goal-based agents, utility-based AI agents, learning agents, and hierarchical AI agents. Each type is designed to address specific business challenges within their designated domains.\\n\\nFinally, the article concludes that AI Agents have the potential to revolutionize various industries, but responsible and beneficial utilization of these agents is essential for enterprises venturing into this transformative journey.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is agent\"\n",
    "sub_docs = vectorstore.similarity_search(query,k=1)\n",
    "sub_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'An Introduction to AI Agents. Artificial Intelligence Agents are the… | by Humans.ai | humansdotai | MediumOpen in appSign upSign inWriteSign upSign inhumansdotai·Humans.ai utilizes blockchain technology to align artificial intelligence with trust, creating a human-centric approach. Our company views AI not as a tool but as a companion, envisioning a collaborative future with humanity.An Introduction to AI AgentsHumans.aiFollow7 min read·Dec 27, 2023--2ListenShareArtificial Intelligence Agents a'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(query,n_results=1)\n",
    "retrieved_docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 13 - ColBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAGatouille makes it as simple to use ColBERT.\n",
    "\n",
    "ColBERT generates a contextually influenced vector for each token in the passages.\n",
    "\n",
    "ColBERT similarly generates vectors for each token in the query.\n",
    "\n",
    "Then, the score of each document is the sum of the maximum similarity of each query embedding to any of the document embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: CUDA is not available. Operations will be run on the CPU.\n",
      "Consider installing a supported CUDA version for optimal performance.\n",
      "Successfully retrieved content for 'Document retrieval'.\n",
      "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
      "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
      "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
      "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
      "--------------------\n",
      "\n",
      "\n",
      "[May 15, 11:13:20] #> Note: Output directory .ragatouille/colbert/indexes/Doc-1 already exists\n",
      "\n",
      "\n",
      "[May 15, 11:13:20] #> Will delete 10 files already at .ragatouille/colbert/indexes/Doc-1 in 20 seconds...\n",
      "[May 15, 11:13:43] [0] \t\t #> Encoding 7 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 15, 11:13:43] [0] \t\t avg_doclen_est = 116.42857360839844 \t len(local_sample) = 7\n",
      "[May 15, 11:13:43] [0] \t\t Creating 256 partitions.\n",
      "[May 15, 11:13:43] [0] \t\t *Estimated* 815 embeddings.\n",
      "[May 15, 11:13:43] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/Doc-1/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: number of training points (775) is less than the minimum recommended (2560)\n",
      "used 6 iterations (0.006s) to cluster 775 items into 256 clusters\n",
      "[0.036, 0.038, 0.038, 0.032, 0.034, 0.034, 0.033, 0.038, 0.029, 0.028, 0.032, 0.03, 0.029, 0.032, 0.036, 0.039, 0.03, 0.026, 0.029, 0.032, 0.029, 0.027, 0.03, 0.038, 0.039, 0.031, 0.031, 0.039, 0.03, 0.041, 0.034, 0.04, 0.03, 0.035, 0.03, 0.03, 0.034, 0.034, 0.027, 0.042, 0.027, 0.044, 0.035, 0.035, 0.034, 0.038, 0.027, 0.03, 0.025, 0.036, 0.028, 0.038, 0.028, 0.026, 0.033, 0.042, 0.04, 0.039, 0.038, 0.04, 0.033, 0.043, 0.029, 0.04, 0.04, 0.044, 0.032, 0.04, 0.033, 0.032, 0.029, 0.024, 0.041, 0.033, 0.041, 0.029, 0.038, 0.031, 0.041, 0.044, 0.037, 0.038, 0.033, 0.037, 0.038, 0.033, 0.039, 0.035, 0.033, 0.029, 0.031, 0.034, 0.032, 0.037, 0.037, 0.032, 0.036, 0.036, 0.032, 0.033, 0.029, 0.035, 0.035, 0.033, 0.036, 0.036, 0.028, 0.025, 0.035, 0.027, 0.042, 0.035, 0.034, 0.038, 0.039, 0.034, 0.031, 0.036, 0.035, 0.032, 0.03, 0.038, 0.026, 0.035, 0.028, 0.035, 0.037, 0.03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 15, 11:13:43] [0] \t\t #> Encoding 7 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.16it/s]\n",
      "1it [00:00,  4.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 848.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 15, 11:13:43] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[May 15, 11:13:43] #> Building the emb2pid mapping..\n",
      "[May 15, 11:13:43] len(emb2pid) = 815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 256/256 [00:00<00:00, 86543.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 15, 11:13:43] #> Saved optimized IVF to .ragatouille/colbert/indexes/Doc-1/ivf.pid.pt\n",
      "Done indexing!\n",
      "Document successfully indexed in RAG.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch  # Import PyTorch\n",
    "import requests\n",
    "from ragatouille import RAGPretrainedModel\n",
    "\n",
    "# Disable tokenizers parallelism to avoid deadlock warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Load the RAG pretrained model\n",
    "RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "\n",
    "# Handle cases where CUDA is not available\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Warning: CUDA is not available. Operations will be run on the CPU.\")\n",
    "    print(\"Consider installing a supported CUDA version for optimal performance.\")\n",
    "\n",
    "def get_wikipedia_page(title: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve the full text content of a Wikipedia page.\n",
    "\n",
    "    :param title: str - Title of the Wikipedia page.\n",
    "    :return: str - Full text content of the page as raw string, or None if page is not found.\n",
    "    \"\"\"\n",
    "    # Wikipedia API endpoint\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "    # Parameters for the API request\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": title,\n",
    "        \"prop\": \"extracts\",\n",
    "        \"explaintext\": True,\n",
    "    }\n",
    "\n",
    "    # Custom User-Agent header to comply with Wikipedia's best practices\n",
    "    headers = {\"User-Agent\": \"RAGatouille_tutorial/0.0.1 (ben@clavie.eu)\"}\n",
    "\n",
    "    try:\n",
    "        # Make the request\n",
    "        response = requests.get(URL, params=params, headers=headers)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses (4xx and 5xx)\n",
    "\n",
    "        # Parse the response\n",
    "        data = response.json()\n",
    "        page = next(iter(data[\"query\"][\"pages\"].values()))\n",
    "\n",
    "        # Return the page content if it exists\n",
    "        return page.get(\"extract\", \"No content found for the page.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error retrieving Wikipedia page '{title}': {e}\")\n",
    "        return None\n",
    "\n",
    "# Retrieve the full document from Wikipedia\n",
    "title = \"Document retrieval\"\n",
    "full_document = get_wikipedia_page(title)\n",
    "\n",
    "# Check if content was successfully retrieved\n",
    "if full_document:\n",
    "    print(f\"Successfully retrieved content for '{title}'.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve content for '{title}'. Exiting.\")\n",
    "    exit(1)\n",
    "\n",
    "# Index the document using RAG\n",
    "try:\n",
    "    RAG.index(\n",
    "        collection=[full_document],\n",
    "        index_name=\"Doc-1\",\n",
    "        max_document_length=180,\n",
    "        split_documents=True,\n",
    "    )\n",
    "    print(\"Document successfully indexed in RAG.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while indexing the document: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4272c151a1441ec96f105ecfd3e34ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index Doc-1 for the first time... This may take a few seconds\n",
      "[May 15, 11:13:56] #> Loading codec...\n",
      "[May 15, 11:13:56] #> Loading IVF...\n",
      "[May 15, 11:13:56] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3216.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 15, 11:13:56] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 533.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What is an example for form-based indexing?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2003, 2019, 2742, 2005, 2433, 1011, 2241, 5950, 2075,\n",
      "        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "Search results: [{'content': '== Variations ==\\nThere are two main classes of indexing schemata for document retrieval systems: form based (or word based), and content based indexing. The document classification scheme (or indexing algorithm) in use determines the nature of the document retrieval system.\\n\\n\\n=== Form based ===\\nForm based document retrieval addresses the exact syntactic properties of a text, comparable to substring matching in string searches. The text is generally unstructured and not necessarily in a natural language, the system could for example be used to process large sets of chemical representations in molecular biology. A suffix tree algorithm is an example for form based indexing.', 'score': 25.85655403137207, 'rank': 1, 'document_id': '9724b829-ff08-47ef-b8a6-141b319add3e', 'passage_id': 2}, {'content': '=== Content based ===\\nThe content based approach exploits semantic connections between documents and parts thereof, and semantic connections between queries and documents. Most content based document retrieval systems use an inverted index algorithm.\\nA signature file is a technique that creates a quick and dirty filter, for example a Bloom filter, that will keep all the documents that match to the query and hopefully a few ones that do not. The way this is done is by creating for each file a signature, typically a hash coded version. One method is superimposed coding. A post-processing step is done to discard the false alarms. Since in most cases this structure is inferior to inverted files in terms of speed, size and functionality, it is not used widely. However, with proper parameters it can beat the inverted files in certain environments.', 'score': 18.951560974121094, 'rank': 2, 'document_id': '9724b829-ff08-47ef-b8a6-141b319add3e', 'passage_id': 3}, {'content': '== Example: PubMed ==\\nThe PubMed form interface features the \"related articles\" search which works through a comparison of words from the documents\\' title, abstract, and MeSH terms using a word-weighted algorithm.\\n\\n\\n== See also ==\\nCompound term processing\\nDocument classification\\nEnterprise search\\nEvaluation measures (information retrieval)\\nFull text search\\nInformation retrieval\\nLatent semantic indexing\\nSearch engine\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\nFaloutsos, Christos; Christodoulakis, Stavros (1984). \"Signature files: An access method for documents and its analytical performance evaluation\". ACM Transactions on Information Systems. 2 (4): 267–288. doi:10.1145/2275.357411. S2CID 8120705.', 'score': 18.90180778503418, 'rank': 3, 'document_id': '9724b829-ff08-47ef-b8a6-141b319add3e', 'passage_id': 4}]\n",
      "[Document(metadata={}, page_content='== Variations ==\\nThere are two main classes of indexing schemata for document retrieval systems: form based (or word based), and content based indexing. The document classification scheme (or indexing algorithm) in use determines the nature of the document retrieval system.\\n\\n\\n=== Form based ===\\nForm based document retrieval addresses the exact syntactic properties of a text, comparable to substring matching in string searches. The text is generally unstructured and not necessarily in a natural language, the system could for example be used to process large sets of chemical representations in molecular biology. A suffix tree algorithm is an example for form based indexing.'), Document(metadata={}, page_content='=== Content based ===\\nThe content based approach exploits semantic connections between documents and parts thereof, and semantic connections between queries and documents. Most content based document retrieval systems use an inverted index algorithm.\\nA signature file is a technique that creates a quick and dirty filter, for example a Bloom filter, that will keep all the documents that match to the query and hopefully a few ones that do not. The way this is done is by creating for each file a signature, typically a hash coded version. One method is superimposed coding. A post-processing step is done to discard the false alarms. Since in most cases this structure is inferior to inverted files in terms of speed, size and functionality, it is not used widely. However, with proper parameters it can beat the inverted files in certain environments.'), Document(metadata={}, page_content='== Example: PubMed ==\\nThe PubMed form interface features the \"related articles\" search which works through a comparison of words from the documents\\' title, abstract, and MeSH terms using a word-weighted algorithm.\\n\\n\\n== See also ==\\nCompound term processing\\nDocument classification\\nEnterprise search\\nEvaluation measures (information retrieval)\\nFull text search\\nInformation retrieval\\nLatent semantic indexing\\nSearch engine\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\nFaloutsos, Christos; Christodoulakis, Stavros (1984). \"Signature files: An access method for documents and its analytical performance evaluation\". ACM Transactions on Information Systems. 2 (4): 267–288. doi:10.1145/2275.357411. S2CID 8120705.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ragatouille import RAGPretrainedModel\n",
    "\n",
    "# Define the device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the existing index **without the 'device' argument**\n",
    "RAG = RAGPretrainedModel.from_index(index_path=\".ragatouille/colbert/indexes/Doc-1\")\n",
    "\n",
    "# Load the index — device will be handled automatically by ragatouille internally\n",
    "RAG = RAGPretrainedModel.from_index(index_path=\".ragatouille/colbert/indexes/Doc-1\")\n",
    "\n",
    "# Perform search\n",
    "results = RAG.search(query=\"What is an example for form-based indexing?\", k=3)\n",
    "print(\"Search results:\", results)\n",
    "\n",
    "# For LangChain retriever\n",
    "retriever = RAG.as_langchain_retriever(k=3)\n",
    "print(retriever.invoke(\"What is an example for form-based indexing?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='== Variations ==\\nThere are two main classes of indexing schemata for document retrieval systems: form based (or word based), and content based indexing. The document classification scheme (or indexing algorithm) in use determines the nature of the document retrieval system.\\n\\n\\n=== Form based ===\\nForm based document retrieval addresses the exact syntactic properties of a text, comparable to substring matching in string searches. The text is generally unstructured and not necessarily in a natural language, the system could for example be used to process large sets of chemical representations in molecular biology. A suffix tree algorithm is an example for form based indexing.'),\n",
       " Document(metadata={}, page_content='== Example: PubMed ==\\nThe PubMed form interface features the \"related articles\" search which works through a comparison of words from the documents\\' title, abstract, and MeSH terms using a word-weighted algorithm.\\n\\n\\n== See also ==\\nCompound term processing\\nDocument classification\\nEnterprise search\\nEvaluation measures (information retrieval)\\nFull text search\\nInformation retrieval\\nLatent semantic indexing\\nSearch engine\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\nFaloutsos, Christos; Christodoulakis, Stavros (1984). \"Signature files: An access method for documents and its analytical performance evaluation\". ACM Transactions on Information Systems. 2 (4): 267–288. doi:10.1145/2275.357411. S2CID 8120705.'),\n",
       " Document(metadata={}, page_content='=== Content based ===\\nThe content based approach exploits semantic connections between documents and parts thereof, and semantic connections between queries and documents. Most content based document retrieval systems use an inverted index algorithm.\\nA signature file is a technique that creates a quick and dirty filter, for example a Bloom filter, that will keep all the documents that match to the query and hopefully a few ones that do not. The way this is done is by creating for each file a signature, typically a hash coded version. One method is superimposed coding. A post-processing step is done to discard the false alarms. Since in most cases this structure is inferior to inverted files in terms of speed, size and functionality, it is not used widely. However, with proper parameters it can beat the inverted files in certain environments.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = RAG.as_langchain_retriever(k=3)\n",
    "retriever.invoke(\"What is an example for form based indexing?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MP-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
