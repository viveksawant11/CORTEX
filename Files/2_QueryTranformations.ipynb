{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_PROJECT'] = 'cortex'\n",
    "\n",
    "# Get keys from the environment\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if langchain_api_key:\n",
    "    os.environ['LANGCHAIN_API_KEY'] = langchain_api_key\n",
    "else:\n",
    "    raise ValueError(\"LANGCHAIN_API_KEY is not set in the environment.\")\n",
    "\n",
    "if groq_api_key:\n",
    "    os.environ['GROQ_API_KEY'] = groq_api_key\n",
    "else:\n",
    "    raise ValueError(\"GROQ_API_KEY is not set in the environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 5 - MULTI QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Set USER_AGENT before making requests\n",
    "os.environ[\"USER_AGENT\"] = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Load Documents\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()\n",
    "\n",
    "# Split - Chunking\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "# Embed\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "# Initialize HuggingFaceEmbeddings\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# Index with FAISS\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=hf_embeddings)\n",
    "\n",
    "# Retrieve\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Query Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. How does LangChain enhance natural language processing tasks?\n",
      "2. In what ways does LangChain improve the efficiency of NLP projects?\n",
      "3. Can you list the advantages of implementing LangChain in NLP workflows?\n",
      "4. What are the key benefits that LangChain brings to the table for NLP applications?\n",
      "5. How can LangChain contribute to the success of natural language processing tasks?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Disable LangSmith tracing to prevent API errors\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\" \n",
    "\n",
    "# Define the template for generating multiple perspectives on the user's question\n",
    "template = \"\"\"\n",
    "You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "\n",
    "Provide these alternative questions separated by newlines.\n",
    "\n",
    "Original question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt template using ChatPromptTemplate\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Define the pipeline for generating alternative questions\n",
    "generate_queries = (\n",
    "    prompt_perspectives  # Use the prompt template\n",
    "    | ChatGroq(temperature=0)  # Use the ChatGroq model with zero temperature (deterministic responses)\n",
    "    | StrOutputParser()  # Parse the output into a clean format (a single string with questions separated by newlines)\n",
    "    | (lambda x: \"\\n\".join([q.strip() for q in x.split(\"\\n\") if q.strip()]))  # Clean and join questions with newlines\n",
    ")\n",
    "\n",
    "# Example: Use the pipeline to generate alternative questions for a given user question\n",
    "user_question = \"What are the benefits of using LangChain for NLP tasks?\"\n",
    "alternative_questions = generate_queries.invoke({\"question\": user_question})\n",
    "\n",
    "# Print the generated alternative questions\n",
    "print(alternative_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# Retrieve\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition for LLM agents refers to the process of breaking down a complex task into smaller, manageable subtasks that can be executed by a large language model (LLM) agent. This allows the agent to handle complex tasks by focusing on one subtask at a time, making it more efficient and effective. The subtasks are often defined in a specific format, such as the ReAct prompt template, which includes explicit steps for the LLM to think, act, and observe. The agent repeats this process until the task is completed. Task decomposition is an important aspect of building LLM-centered agents, as it helps to address common limitations such as hallucination and inefficient planning.\n"
     ]
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG template\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatGroq(temperature=0)\n",
    "\n",
    "# Define the final RAG chain\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \"question\": itemgetter(\"question\")}  # Ensure the mapping is correct\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: \"\\n\".join([q.strip() for q in x.split(\"\\n\") if q.strip()]))\n",
    ")\n",
    "\n",
    "# Define the question\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "\n",
    "# Invoke the chain with the question and get the result\n",
    "result = final_rag_chain.invoke({\"question\": question})\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 6 - RAG-FUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# RAG-Fusion: Related\n",
    "template = \"\"\"\n",
    "You are a helpful assistant tasked with generating multiple search queries based on a single input query. \n",
    "The goal is to create queries that are semantically related to the input while capturing different aspects of the topic.\n",
    "\n",
    "Input Query: {question}\n",
    "\n",
    "Output: Provide exactly 4 related search queries, each on a new line.\n",
    "\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Define the query generation pipeline\n",
    "generate_queries = (\n",
    "    prompt_rag_fusion\n",
    "    | ChatGroq(temperature=0)\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: [\n",
    "        query.strip().lstrip(\"1234567890. \")  # Remove numbering and extra spaces\n",
    "        for query in x.split(\"\\n\") if query.strip()  # Remove empty lines\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of retrieved documents: 9\n"
     ]
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"Applies Reciprocal Rank Fusion (RRF) to combine ranked document lists.\"\"\"\n",
    "    fused_scores = {}\n",
    "\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)  # Serialize document for use as dictionary key\n",
    "            fused_scores[doc_str] = fused_scores.get(doc_str, 0) + 1 / (rank + k)\n",
    "\n",
    "    # Sort by score in descending order and deserialize documents\n",
    "    return [\n",
    "        (loads(doc), score) for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "# RAG Fusion Retrieval Chain\n",
    "retrieval_chain_rag_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "\n",
    "# Invoke the chain with a question\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "\n",
    "# Output the length of the fused document list\n",
    "print(f\"Number of retrieved documents: {len(docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM agents is the process of breaking down a complex task into smaller and simpler steps. This can be done using techniques such as Chain of Thought (CoT) or Tree of Thoughts, where the model is instructed to \"think step by step\" and generate multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier or majority vote. Task decomposition can also be done using simple prompting, task-specific instructions, or human inputs.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain_rag_fusion, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: \"\\n\".join([line.strip() for line in x.split(\"\\n\") if line.strip()]))\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 7 - DECOMPOSITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Decomposition Template\n",
    "template = \"\"\"\n",
    "You are a helpful assistant tasked with breaking down a complex input question into smaller, focused sub-questions. \n",
    "Each sub-question should address a specific aspect of the main question, allowing them to be answered in isolation.\n",
    "\n",
    "Input: {question}\n",
    "\n",
    "Your goal:\n",
    "- Decompose the input question into exactly 3 relevant and concise sub-questions.\n",
    "- Ensure each sub-question is clear, non-overlapping, and focused on a distinct aspect of the input.\n",
    "\n",
    "Output:\n",
    "1. [First sub-question]\n",
    "2. [Second sub-question]\n",
    "3. [Third sub-question]\n",
    "\"\"\"\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What are the key components of a Language Model (LLM) that contribute to its use in an autonomous agent system?\n",
      "2. How does an autonomous agent system incorporate an LLM for decision-making and task execution?\n",
      "3. What are the main supporting systems or components required for an LLM-powered autonomous agent to function effectively?\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM\n",
    "llm = ChatGroq(temperature=0)\n",
    "\n",
    "# Chain for generating sub-questions via decomposition\n",
    "generate_queries_decomposition = (\n",
    "    prompt_decomposition  # The prompt template\n",
    "    | llm  # Language model to process the prompt\n",
    "    | StrOutputParser()  # Parses the LLM output to a string\n",
    "    | (lambda x: [q.strip() for q in x.split(\"\\n\") if q.strip()])  # Clean and split into a list of sub-questions\n",
    ")\n",
    "\n",
    "# Input Question\n",
    "question = \"What are the main components of an LLM-powered autonomous agent system?\"\n",
    "\n",
    "# Run the Chain\n",
    "try:\n",
    "    questions = generate_queries_decomposition.invoke({\"question\": question})\n",
    "    # Print the generated sub-questions\n",
    "    print(\"\\n\".join(questions))\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a helpful assistant tasked with answering a given question using the provided background question-answer pairs and additional context.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Background Question-Answer Pairs:\n",
    "{q_a_pairs}\n",
    "\n",
    "Additional Context:\n",
    "{context}\n",
    "\n",
    "Using the above information, provide a clear and concise answer to the question: {question}\n",
    "\"\"\"\n",
    "\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Question: 1. What are the key components of a Language Model (LLM) that contribute to its use in an autonomous agent system?\n",
      "Answer: The key components of a Language Model (LLM) that contribute to its use in an autonomous agent system include Planning, Memory, and the ability to call external symbolic tools. Planning involves subgoal and decomposition, as well as reflection and refinement. Memory allows the agent to store and retrieve past information. The LLM's capability to determine when and how to use external symbolic tools, such as a calculator or API, is also crucial for its effective use in an autonomous agent system.\n",
      "---\n",
      "Question: 2. How does an autonomous agent system incorporate an LLM for decision-making and task execution?\n",
      "Answer: An autonomous agent system incorporates a Language Model (LLM) for decision-making and task execution by utilizing its key components, which include Planning, Memory, and the ability to call external symbolic tools. The LLM can decompose complex tasks into smaller, manageable steps using techniques like Chain of Thought (CoT) or Tree of Thoughts. This process transforms big tasks into multiple tasks and sheds light on the model's thinking process. Task decomposition can also be done using simple prompting, task-specific instructions, or human inputs. Additionally, an external classical planner can be used for long-horizon planning, with the LLM translating the problem into PDDL, requesting a classical planner to generate a PDDL plan, and then translating the PDDL plan back into natural language. Self-reflection is another vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. ReAct integrates reasoning and acting within the LLM by extending the action space to include task-specific discrete actions and the language space, enabling the LLM to interact with the environment and generate reasoning traces in natural language.\n",
      "---\n",
      "Question: 3. What are the main supporting systems or components required for an LLM-powered autonomous agent to function effectively?\n",
      "Answer: An LLM-powered autonomous agent requires several main supporting components to function effectively:\n",
      "\n",
      "1. Planning: This involves subgoal and decomposition, reflection and refinement, and self-criticism and self-reflection over past actions. It enables the agent to break down large tasks into smaller, manageable subgoals and improve the quality of final results.\n",
      "\n",
      "2. Memory: This allows the agent to store and retrieve past information, which is crucial for decision-making and task execution.\n",
      "\n",
      "3. External symbolic tools: The LLM's capability to determine when and how to use external symbolic tools, such as a calculator or API, is essential for its effective use in an autonomous agent system.\n",
      "\n",
      "4. Task decomposition techniques: Chain of Thought (CoT) and Tree of Thoughts are two techniques used for decomposing complex tasks into smaller, manageable steps. CoT transforms big tasks into multiple manageable tasks and sheds light on the model's thinking process, while Tree of Thoughts explores multiple reasoning possibilities at each step.\n",
      "\n",
      "5. Human inputs: Task decomposition can also be done using human inputs, which can provide specific instructions for achieving certain goals.\n",
      "\n",
      "These components work together to enable the LLM to decompose complex tasks, plan ahead, learn from past actions, and interact with the environment effectively.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"Format a question and answer pair as a string.\"\"\"\n",
    "    return f\"Question: {question}\\nAnswer: {answer}\\n\"\n",
    "\n",
    "# Initialize the language model (LLM)\n",
    "llm = ChatGroq(temperature=0)\n",
    "\n",
    "# Initialize Q&A pairs as an empty string\n",
    "q_a_pairs = \"\"\n",
    "\n",
    "# Loop through the list of questions and process each one\n",
    "for q in questions:\n",
    "    # Define the RAG chain for retrieving and answering\n",
    "    rag_chain = (\n",
    "        {\n",
    "            \"context\": itemgetter(\"question\") | retriever,  # Retrieve context for the current question\n",
    "            \"question\": itemgetter(\"question\"),             # Extract the current question\n",
    "            \"q_a_pairs\": itemgetter(\"q_a_pairs\")            # Include existing Q&A pairs\n",
    "        }\n",
    "        | decomposition_prompt  # Apply the decomposition prompt\n",
    "        | llm                   # Use the LLM to generate an answer\n",
    "        | StrOutputParser()     # Parse the output into a clean string\n",
    "    )\n",
    "\n",
    "    # Generate an answer for the current question\n",
    "    answer = rag_chain.invoke({\"question\": q, \"q_a_pairs\": q_a_pairs})\n",
    "\n",
    "    # Format the question and answer pair\n",
    "    q_a_pair = format_qa_pair(q, answer)\n",
    "\n",
    "    # Append the new Q&A pair to the existing pairs\n",
    "    q_a_pairs += f\"\\n---\\n{q_a_pair.strip()}\"\n",
    "\n",
    "# Print the final Q&A pairs (optional)\n",
    "print(q_a_pairs.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer Individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bg/7gm4yt417px42myyczdlqf1h0000gn/T/ipykernel_53172/4103660154.py:33: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(sub_question)\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Pull the RAG prompt template from the hub\n",
    "prompt_rag = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def retrieve_and_rag(question, prompt_rag, sub_question_generator_chain):\n",
    "    \"\"\"\n",
    "    Perform RAG (Retrieve and Generate) for each sub-question.\n",
    "    \n",
    "    Args:\n",
    "        question (str): The main input question.\n",
    "        prompt_rag: The RAG prompt template.\n",
    "        sub_question_generator_chain: A chain that generates sub-questions.\n",
    "        retriever: A retriever object to fetch relevant documents.\n",
    "        llm: The language model for answering questions.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A list of answers and the corresponding sub-questions.\n",
    "    \"\"\"\n",
    "    # Generate sub-questions from the input question\n",
    "    sub_questions = sub_question_generator_chain.invoke({\"question\": question})\n",
    "\n",
    "    # Initialize a list to store answers for each sub-question\n",
    "    rag_results = []\n",
    "\n",
    "    # Process each sub-question\n",
    "    for sub_question in sub_questions:\n",
    "        # Retrieve documents relevant to the sub-question\n",
    "        rretrieved_docs = retriever.invoke(sub_question)\n",
    "\n",
    "        # Generate an answer using the RAG prompt, LLM, and retrieved documents\n",
    "        answer = (\n",
    "            prompt_rag  # Apply the RAG prompt\n",
    "            | llm       # Pass it through the language model\n",
    "            | StrOutputParser()  # Parse the LLM output into a clean string\n",
    "        ).invoke({\"context\": retrieved_docs, \"question\": sub_question})\n",
    "\n",
    "        # Append the generated answer to the results list\n",
    "        rag_results.append(answer)\n",
    "\n",
    "    return rag_results, sub_questions\n",
    "\n",
    "# Wrap the retrieval and RAG process in a RunnableLambda for integration into a chain\n",
    "answers, questions = retrieve_and_rag(question, prompt_rag, generate_queries_decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main components of a LLM-powered autonomous agent system include Planning, Memory, Reflection and Refinement, and an optional external classical planner. Planning is responsible for breaking down large tasks into smaller, manageable subgoals and planning ahead. Memory aids in storing and retrieving information for the agent. Reflection and Refinement enable the agent to learn from past actions, critique them, and refine future steps. An external classical planner can be used for long-horizon planning. These components work together to enable the agent to perceive, understand, make decisions, and execute actions in its environment.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "def format_qa_pairs(questions, answers):\n",
    "    \"\"\"\n",
    "    Format a list of questions and their corresponding answers into a structured string.\n",
    "\n",
    "    Args:\n",
    "        questions (list): List of questions.\n",
    "        answers (list): List of answers corresponding to the questions.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted string of Q&A pairs.\n",
    "    \"\"\"\n",
    "    return \"\\n\\n\".join(\n",
    "        f\"Question {i}: {q}\\nAnswer {i}: {a}\" for i, (q, a) in enumerate(zip(questions, answers), start=1)\n",
    "    ).strip()\n",
    "\n",
    "# Format the Q&A pairs to create the context\n",
    "context = format_qa_pairs(questions, answers)\n",
    "\n",
    "# Define the prompt template for synthesizing an answer\n",
    "template = \"\"\"\n",
    "Here is a set of Q+A pairs:\n",
    "\n",
    "{context}\n",
    "\n",
    "Use these to synthesize a clear and concise answer to the following question:\n",
    "\n",
    "{question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Define the RAG chain\n",
    "final_rag_chain = (\n",
    "    prompt  # Use the prompt template\n",
    "    | llm  # Pass the input through the language model\n",
    "    | StrOutputParser()  # Parse the output into a clean string\n",
    ")\n",
    "\n",
    "# Invoke the chain with the given context and question\n",
    "result = final_rag_chain.invoke({\"context\": context, \"question\": question})\n",
    "\n",
    "# Output the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 8 - STEP BACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "\n",
    "# Define few-shot examples\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"What can the members of The Police do?\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Sindel was born in what country?\",\n",
    "        \"output\": \"What is Jan Sindel’s personal history?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Transform examples into example messages using a message prompt template\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a few-shot prompt template with the example prompt and examples\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# Combine the system message, few-shot examples, and user question into the final prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert in world knowledge. Your task is to reframe a specific question into a more generic, step-back question that is easier to answer. Here are a few examples:\"\"\",\n",
    "        ),\n",
    "        # Add few-shot examples\n",
    "        few_shot_prompt,\n",
    "        # Add the user question\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How can a LLM agent break down a task into smaller, manageable parts?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries_step_back = prompt | ChatGroq(temperature=0) | StrOutputParser()\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "generate_queries_step_back.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition for LLM (Latent Dirichlet Allocation) agents refers to the process of breaking down a complex task into smaller, manageable subtasks. This allows the agent to plan and execute the task more effectively. There are several methods for task decomposition in LLM agents:\n",
      "\n",
      "1. Chain of Thought (CoT): This is a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to \"think step by step\" to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and sheds light on the interpretation of the model's thinking process.\n",
      "2. Tree of Thoughts: This extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "3. Prompting: Task decomposition can be done by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\"\n",
      "4. Task-specific instructions: Task decomposition can also be done using task-specific instructions, such as \"Write a story outline.\" for writing a novel.\n",
      "5. Human inputs: Task decomposition can also be done with human inputs.\n",
      "\n",
      "In addition, LLM agents can parse user input into several tasks, each with a task type, ID, dependencies, and arguments. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task\\_id\" refers to the generated text image, audio and video in the dependency task with id as task\\_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can't be parsed, the agent will reply with an empty JSON. The chat history is recorded and can be used for task planning.\n",
      "\n",
      "LLM agents can also distribute tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from, and task type based filtration is needed due to the limited context length.\n"
     ]
    }
   ],
   "source": [
    "# Define the response prompt template\n",
    "response_prompt_template = \"\"\"\n",
    "You are an expert in world knowledge. I will ask you a question. Your response should be comprehensive and aligned with the provided contexts if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "# Normal Context:\n",
    "{normal_context}\n",
    "\n",
    "# Step-Back Context:\n",
    "{step_back_context}\n",
    "\n",
    "# Original Question:\n",
    "{question}\n",
    "\n",
    "# Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Create the response prompt\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
    "\n",
    "# Define the chain for context retrieval and response generation\n",
    "chain = (\n",
    "    {\n",
    "        # Retrieve normal context using the original question\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
    "        # Retrieve step-back context using the step-back question\n",
    "        \"step_back_context\": generate_queries_step_back | retriever,\n",
    "        # Pass through the original question\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt  # Generate a prompt with the retrieved context and question\n",
    "    | ChatGroq(temperature=0)  # Generate the response using the LLM\n",
    "    | StrOutputParser()  # Parse the response into a clean string\n",
    ")\n",
    "\n",
    "# Invoke the chain with the input question\n",
    "result = chain.invoke({\"question\": question})\n",
    "\n",
    "# Print the generated response\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 9 - HyDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition is a crucial aspect of building large language models (LLMs) that can effectively perform complex tasks. It involves breaking down a complex task into smaller, manageable subtasks that the LLM can handle more efficiently. This process is similar to the way humans approach complex problems by dividing them into smaller, more manageable parts.\n",
      "\n",
      "In the context of LLMs, task decomposition enables the model to focus on specific aspects of a task, reducing the cognitive load and improving the overall performance. For example, if the task is to write a scientific paper, the LLM can be decomposed into subtasks such as:\n",
      "\n",
      "1. Generating an outline for the paper\n",
      "2. Conducting literature reviews and summarizing relevant sources\n",
      "3. Developing arguments and evidence to support the paper's thesis\n",
      "4. Writing the introduction, body, and conclusion of the paper\n",
      "5. Formatting the paper according to the required style\n",
      "\n",
      "By breaking down the task in this way, the LLM can focus on one subtask at a time, reducing the complexity of the overall task and improving the quality of the output. Additionally, task decomposition allows for greater flexibility in the model's behavior, enabling it to adapt to different types of tasks and contexts.\n",
      "\n",
      "In summary, task decomposition is a key technique for building LLMs that can effectively perform complex tasks. By breaking down a complex task into smaller, manageable subtasks, the LLM can focus on specific aspects of the task, reducing the cognitive load and improving the overall performance.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Define the HyDE document generation template\n",
    "template = \"\"\"\n",
    "Please write a scientific paper passage to answer the following question:\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Passage:\n",
    "\"\"\"\n",
    "\n",
    "# Create a prompt template using ChatPromptTemplate\n",
    "prompt_hyde = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Define the document generation chain\n",
    "generate_docs_for_retrieval = (\n",
    "    prompt_hyde  # Use the HyDE prompt template\n",
    "    | ChatGroq(temperature=0)  # Generate the document using the language model\n",
    "    | StrOutputParser()  # Parse the LLM output into a clean string\n",
    ")\n",
    "\n",
    "# Define the question\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "\n",
    "# Invoke the chain to generate the passage\n",
    "generated_passage = generate_docs_for_retrieval.invoke({\"question\": question})\n",
    "\n",
    "# Print the generated passage\n",
    "print(generated_passage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='bce32ac7-6491-4ee1-b8d6-a70459a5f1af', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
       " Document(id='150dea50-bbde-484c-b420-bf635a80525a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.'),\n",
       " Document(id='45eda60f-273e-49cb-931e-3f569d3ba650', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Or\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).'),\n",
       " Document(id='a9a1a577-1fae-4c18-9eae-a2b1cbfec4fa', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve\n",
    "retrieval_chain = generate_docs_for_retrieval | retriever \n",
    "retrieved_docs = retrieval_chain.invoke({\"question\":question})\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task decomposition for LLM (Latent Dirichlet Allocation) agents refers to the process of breaking down a complex task into smaller, manageable subtasks. This can be done using simple prompting techniques, task-specific instructions, or human inputs. The 'Chain of Thought' (CoT) technique, as described in the document, is a standard prompting technique for enhancing model performance on complex tasks. It instructs the model to 'think step by step' to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. The 'Tree of Thoughts' (ToT) extends CoT by exploring multiple reasoning possibilities at each step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Define the RAG prompt template\n",
    "template = \"\"\"\n",
    "Answer the following question based on the provided context:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# Create a prompt from the template\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Define the RAG chain\n",
    "final_rag_chain = (\n",
    "    prompt  # Generate the prompt using the template\n",
    "    | ChatGroq(temperature=0)  # Use the LLM to process the prompt\n",
    "    | StrOutputParser()  # Parse the output into a clean string\n",
    ")\n",
    "\n",
    "# Invoke the RAG chain with the context and question\n",
    "result = final_rag_chain.invoke({\n",
    "    \"context\": retrieved_docs,  # The retrieved documents as context\n",
    "    \"question\": question  # The question to be answered\n",
    "})\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MP-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
